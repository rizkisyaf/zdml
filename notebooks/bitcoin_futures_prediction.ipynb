{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b4e0b84",
   "metadata": {},
   "source": [
    "# Bitcoin Perpetual Futures Prediction\n",
    "\n",
    "This notebook demonstrates the implementation of a Bitcoin perpetual futures prediction system using LSTM networks and order book data.\n",
    "\n",
    "## Table of Contents\n",
    "1. Setup and Data Loading\n",
    "2. Data Preprocessing\n",
    "3. Feature Engineering\n",
    "4. Model Training\n",
    "5. Making Predictions\n",
    "6. Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c9e5625",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b9a5c4",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading\n",
    "\n",
    "First, we'll load the order book data and check its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d8aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our modules\n",
    "from src.data.preprocessing import load_orderbook_data, preprocess_data, prepare_training_data\n",
    "from src.utils.features import extract_features\n",
    "from src.visualization.visualize import plot_order_book_snapshot\n",
    "\n",
    "# Load data\n",
    "data_path = '../futures_orderbook_data.csv'\n",
    "if not os.path.exists(data_path):\n",
    "    logger.error(f\"Data file not found: {data_path}\")\n",
    "    logger.info(\"Please download the data file and place it in the correct directory.\")\n",
    "else:\n",
    "    df = load_orderbook_data(data_path)\n",
    "    logger.info(f\"Loaded {len(df)} rows of order book data with {len(df.columns)} columns\")\n",
    "\n",
    "# Display first few rows (showing only first level for brevity)\n",
    "columns_to_show = ['timestamp', 'bid_price1', 'bid_qty1', 'ask_price1', 'ask_qty1']\n",
    "df[columns_to_show].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a4f017",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "Now we'll preprocess the data and extract features from all 10 levels of the order book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88424d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "window_size = 20\n",
    "features_df = preprocess_data(df, window_size)\n",
    "logger.info(f\"Preprocessed data has {len(features_df)} rows and {features_df.shape[1]} columns\")\n",
    "\n",
    "# Display first few rows of preprocessed data (key features)\n",
    "key_features = ['mid_price', 'weighted_mid_price', 'spread', 'imbalance', 'liquidity_imbalance', 'price_range']\n",
    "features_df[key_features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f75d6d",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "Let's prepare the sequences for our LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230797df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "sequence_length = 100\n",
    "prediction_horizon = 1\n",
    "test_size = 0.2\n",
    "val_size = 0.1\n",
    "\n",
    "data = prepare_training_data(\n",
    "    features_df,\n",
    "    sequence_length=sequence_length,\n",
    "    prediction_horizon=prediction_horizon,\n",
    "    test_size=test_size,\n",
    "    val_size=val_size\n",
    ")\n",
    "\n",
    "# Print data shapes\n",
    "print(\"Data shapes:\")\n",
    "print(f\"X_train: {data['X_train'].shape}\")\n",
    "print(f\"y_train: {data['y_train'].shape}\")\n",
    "print(f\"X_val: {data['X_val'].shape}\")\n",
    "print(f\"y_val: {data['y_val'].shape}\")\n",
    "print(f\"X_test: {data['X_test'].shape}\")\n",
    "print(f\"y_test: {data['y_test'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b48a652",
   "metadata": {},
   "source": [
    "## 4. Model Training\n",
    "\n",
    "Now we'll train our LSTM model with attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dd136e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import train_model\n",
    "\n",
    "# Save processed data for training\n",
    "processed_data_path = 'processed_data.pkl'\n",
    "with open(processed_data_path, 'wb') as f:\n",
    "    import pickle\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "# Create model directory\n",
    "model_dir = 'saved_models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Train model\n",
    "results = train_model(\n",
    "    data_path=processed_data_path,\n",
    "    model_save_dir=model_dir,\n",
    "    batch_size=512,\n",
    "    epochs=10,  # Reduced for demonstration\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=1e-5,\n",
    "    patience=3,\n",
    "    use_gpu=torch.cuda.is_available(),\n",
    "    loss_type='hybrid',\n",
    "    output_size=3,\n",
    "    sequence_length=sequence_length,\n",
    "    prediction_horizon=prediction_horizon\n",
    ")\n",
    "\n",
    "# Print model architecture\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(f\"Input size: {data['X_train'].shape[2]} features\")\n",
    "print(f\"Hidden size: {512 if data['X_train'].shape[2] > 100 else 256}\")\n",
    "print(f\"Projection size: 128\")\n",
    "print(f\"Number of LSTM layers: 3\")\n",
    "print(f\"Number of attention heads: 8\")\n",
    "print(f\"Output size: 3 (price, direction, volatility)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceffd3a2",
   "metadata": {},
   "source": [
    "## 5. Making Predictions\n",
    "\n",
    "Let's use our trained model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32af7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.predict import run_prediction\n",
    "\n",
    "# Create prediction directory\n",
    "prediction_dir = 'prediction_results'\n",
    "os.makedirs(prediction_dir, exist_ok=True)\n",
    "\n",
    "# Run prediction\n",
    "prediction_results = run_prediction(\n",
    "    model_path=results['model_path'],\n",
    "    data_path=data_path,\n",
    "    output_dir=prediction_dir,\n",
    "    window_size=window_size,\n",
    "    use_gpu=torch.cuda.is_available(),\n",
    "    batch_size=512,\n",
    "    visualize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a168922",
   "metadata": {},
   "source": [
    "## 6. Evaluation and Visualization\n",
    "\n",
    "Finally, let's evaluate our model's performance and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec12adbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print metrics\n",
    "print(\"Model Metrics:\")\n",
    "for k, v in prediction_results['metrics'].items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "print(\"\\nTrading Metrics:\")\n",
    "for k, v in prediction_results['trading_metrics'].items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# Load and display saved visualizations\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "img = plt.imread(os.path.join(prediction_dir, 'price_predictions.png'))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('Price Predictions')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "img = plt.imread(os.path.join(prediction_dir, 'direction_accuracy.png'))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('Direction Accuracy')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "img = plt.imread(os.path.join(prediction_dir, 'trading_performance.png'))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('Trading Performance')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "img = plt.imread(os.path.join(prediction_dir, 'order_book_first.png'))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('Order Book Snapshot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
