{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5da9b498",
   "metadata": {},
   "source": [
    "# Bitcoin Futures Prediction Model Training\n",
    "\n",
    "This notebook trains the LSTM model for Bitcoin futures prediction using Google Colab's GPU and pushes it to Hugging Face Hub.\n",
    "\n",
    "## Overview\n",
    "1. Setup Environment\n",
    "2. Load and Preprocess Data\n",
    "3. Train Model\n",
    "4. Push to Hugging Face Hub\n",
    "\n",
    "Make sure you have:\n",
    "- Your Hugging Face token ready\n",
    "- The order book data file (`futures_orderbook_data.csv`)\n",
    "- Access to your Hugging Face Space (rizkisyaf/zdml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b19d865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers huggingface_hub gradio torch pandas numpy scikit-learn matplotlib seaborn tqdm pywavelets tensorboard pytest jupyter\n",
    "\n",
    "# Clone your repository\n",
    "!git clone https://github.com/rizkisyaf/zdml.git\n",
    "%cd DATARESEARCH\n",
    "\n",
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from huggingface_hub import login\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df0314d",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "Upload your order book data and prepare it for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b78245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data file\n",
    "from google.colab import files\n",
    "print(\"Please upload futures_orderbook_data.csv\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Save the uploaded file\n",
    "!mkdir -p data\n",
    "!mv futures_orderbook_data.csv data/futures_orderbook_data.csv\n",
    "\n",
    "# Load and preprocess data\n",
    "from src.data.preprocessing import load_orderbook_data, preprocess_data, prepare_training_data, save_processed_data\n",
    "\n",
    "# Load data\n",
    "df = load_orderbook_data('data/futures_orderbook_data.csv')\n",
    "print(f\"Loaded {len(df)} rows of order book data\")\n",
    "\n",
    "# Preprocess data\n",
    "features_df = preprocess_data(df, window_size=20)\n",
    "print(f\"Preprocessed data shape: {features_df.shape}\")\n",
    "\n",
    "# Display first few rows of key features\n",
    "key_features = ['mid_price', 'weighted_mid_price', 'spread', 'imbalance', 'liquidity_imbalance', 'price_range']\n",
    "print(\"\n",
    "First few rows of key features:\")\n",
    "print(features_df[key_features].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f9e5e8",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Prepare sequences for LSTM training and split into train/val/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af21b716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "data = prepare_training_data(\n",
    "    features_df,\n",
    "    sequence_length=100,\n",
    "    prediction_horizon=1,\n",
    "    test_size=0.2,\n",
    "    val_size=0.1\n",
    ")\n",
    "\n",
    "# Save processed data\n",
    "save_processed_data(data, 'processed_data.pkl')\n",
    "\n",
    "print(\"Data shapes:\")\n",
    "print(f\"X_train: {data['X_train'].shape}\")\n",
    "print(f\"y_train: {data['y_train'].shape}\")\n",
    "print(f\"X_val: {data['X_val'].shape}\")\n",
    "print(f\"y_val: {data['y_val'].shape}\")\n",
    "print(f\"X_test: {data['X_test'].shape}\")\n",
    "print(f\"y_test: {data['y_test'].shape}\")\n",
    "\n",
    "# Print feature names\n",
    "print(\"\n",
    "Features used for training:\")\n",
    "for i, feature in enumerate(data['feature_names']):\n",
    "    print(f\"{i+1}. {feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56087738",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Train the LSTM model using GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d4dafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to Hugging Face\n",
    "from huggingface_hub import login\n",
    "print(\"Please enter your Hugging Face token when prompted\")\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aea3a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training modules\n",
    "from src.models.lstm_model import OrderBookLSTM, OrderBookConfig, HybridLoss\n",
    "from src.train import train_model\n",
    "from src.utils.push_to_hub import push_model_to_hub\n",
    "\n",
    "# Set training parameters\n",
    "training_params = {\n",
    "    'data_path': 'processed_data.pkl',\n",
    "    'model_save_dir': 'saved_models',\n",
    "    'batch_size': 512,\n",
    "    'epochs': 100,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-5,\n",
    "    'patience': 10,\n",
    "    'use_gpu': torch.cuda.is_available(),\n",
    "    'loss_type': 'hybrid',\n",
    "    'output_size': 3,  # Price, direction, volatility\n",
    "    'sequence_length': 100,\n",
    "    'prediction_horizon': 1\n",
    "}\n",
    "\n",
    "# Create model directory\n",
    "os.makedirs(training_params['model_save_dir'], exist_ok=True)\n",
    "\n",
    "# Train model\n",
    "print(\"Starting model training...\")\n",
    "results = train_model(**training_params)\n",
    "\n",
    "print(\"\n",
    "Training completed!\")\n",
    "print(f\"Model saved to: {results['model_path']}\")\n",
    "print(\"\n",
    "Test metrics:\")\n",
    "for k, v in results['test_metrics'].items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# Push model to Hugging Face Hub\n",
    "print(\"\n",
    "Pushing model to Hugging Face Hub...\")\n",
    "model_url = push_model_to_hub(\n",
    "    model_path=results['model_path'],\n",
    "    repo_name=\"zdml\",\n",
    "    organization=\"rizkisyaf\"\n",
    ")\n",
    "\n",
    "print(f\"\n",
    "Model successfully pushed to {model_url}\")\n",
    "print(\"You can now use the model in your Gradio app!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c77194d",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "Let's visualize the model's predictions and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861f7b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization.visualize import (\n",
    "    plot_price_predictions,\n",
    "    plot_direction_accuracy,\n",
    "    plot_trading_performance,\n",
    "    plot_order_book_snapshot\n",
    ")\n",
    "\n",
    "# Load test predictions\n",
    "test_preds = results['test_predictions']\n",
    "test_targets = data['y_test']\n",
    "\n",
    "# Plot predictions\n",
    "plot_price_predictions(\n",
    "    test_targets,\n",
    "    test_preds,\n",
    "    title='Bitcoin Price Predictions (Test Set)'\n",
    ")\n",
    "\n",
    "# Plot direction accuracy\n",
    "plot_direction_accuracy(\n",
    "    test_targets,\n",
    "    test_preds,\n",
    "    title='Direction Prediction Accuracy'\n",
    ")\n",
    "\n",
    "# Plot trading performance\n",
    "plot_trading_performance(\n",
    "    results['test_returns'],\n",
    "    results['test_positions'],\n",
    "    data['test_prices'],\n",
    "    title='Trading Performance (Test Set)'\n",
    ")\n",
    "\n",
    "# Plot sample order book\n",
    "plot_order_book_snapshot(\n",
    "    df,\n",
    "    index=len(df)//2,  # Middle of the dataset\n",
    "    title='Sample Order Book Snapshot'\n",
    ")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
